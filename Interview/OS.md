# Operating System(운영체제)

<details>
  <summary>운영체제란 무엇인가요?</summary>
  <br>

- `Operating System`으로 흔히 `OS`라 부르며 사용자가 컴퓨터를 편리하고 효과적으로  사용할 수 있도록 환경을 제공하는 시스템 소프트웨어입니다.
- ### 종류
    - UNIX
    - Linux
    - Windows
- ### 역할
    - `프로세스 관리` : 운영체제에서 적용하는 응용 프로그램을 관리
    - `저장장치 관리` : 1차 저장장치(Main Memory)와 2차 저장장치(HDD, NAND Flash Memory 등)를 관리하는 기능
    - `네트워킹` : 네트워크 프로토콜 지원
    - `사용자 관리` : 파일 및 시스템 자원 접근 권한 지정하여 사용자 관리
    - `디바이스 드라이버` : 시스템 자원, 하트웨어 관리 / `하드웨어를 추상화 해주는 계층`

</details>

<details>
  <summary>프로세스 주소 공간은 어떻게 이루어져 있고 왜 나누었나요?/메모리 영역은 어떻게 나눠져있나요?</summary>
  <br>

- 최대한 데이터를 공유하여 메모리 사용량을 줄여야 하기에 나누었습니다.

- ### 프로세스 주소 공간(메모리 영역)
    - `Code` : 코드 자체를 구성하는 메모리 영역
    - `Data` : 전역변수, 정적변수, 배열 등이 할당되는 영역
    - `Heap` : 동적 할달시 사용되는 영역
    - `Stack` : 함수의 호출 정보, 지역변수, 매개변수 등이 저장되는 영역

</details>

<details>
  <summary>프로세스와 스레드를 각각 설명하고 차이를 말씀해 주세요.</summary>
  <br>

- **프로세스** : 메모리 상에서 실행중인 프로그램
- **스레드** : 프로세스 안에서 실행되는 흐름단위

- 하나의 프로세스 생성시, 기본적으로 하나의 스레드 생성
- 스레드는 프로세스 내에서 Stack만 따로 할당받고, 그 이외의 메모리 영역(Code, Data, Heap) 영역을 공유

</details>

<details>
  <summary>멀티 프로세스와 멀티 스레드의 장단점을 설명해 주세요.</summary>
  <br>

- 멀티 프로세스
  - 장점 : 안정성(OS 차원에서 해결)
  - 단점 : 각각 독립된 메모리 영역을 가지고 있음<br>
          => 작엄량 증가<br>
          => `Context Switching` 증가<br>
          => 오버헤드 발생<br>
          => 성능 저하<br>

- 멀티 스레드
  - 장점 : 메모리 공유, 시간 및 자원 손실 감소
  - 단점 : 공유메모리로 안정성 문제 발생<br>
          -> 하나의 스레드가 데이터 공간을 망가뜨리면 모든 스레드가 작동 불능<br>
          -> **But**, **Critical Section 기법**을 통해 대비 가능<br>

  **Critical Section 기법** : 하나의 스레드가 공유 데이터 값을 변경하는 시점에 다른 스레드가 그 값을 읽으려 할 때 발생하는 문제를 해결하기 위한 동기화 과정

</details>

<details>
  <summary>인터럽트(Interrupt)란 무엇인가요?</summary>
  <br>

- 프로그램 실행 도중 예기치 않은 상황이 발생하여 현재 실행중인 작업을 즉시 중단하고 발생된 상황에 대한 우선 처리가 필요함을 CPU에게 알리는 것입니다.

- ### 종류
  - **외부 인터럽트** : 입출력 장치, 차이밍 장치, 전원 등 외부적 요인으로 발생
  - **내부 인터럽트(Trap)** : `Trap`이라 부르며 오버플로우, 명령어 오사용 등 잘못된 명령이나 데이터를 사용할 때 발생
  - **소프트웨어 인터럽트** : 프로그램 처리 중 명령의 요청에 의해 발생한 것

- 내외부 인터럽트는 CPU의 하드웨어 신호에 의해 발생하며 소프트웨어 인터럽트는 명령어 수행에 의해 발생합니다.
- 인터럽트가 없다면 `폴링(Polling)` 사용
  - `폴링(Poliing)` : 사용자가 명령어를 사용해 수시로 확인해서 변화를 알아내는 방식

</details>

<details>
  <summary>시스템 콜(System Call)에 대하여 설명해 주세요.</summary>
  <br>

- 응용 프로그램의 요청에 따라 kernel에 접근하기 위한 인터페이스입니다.

- ### 유형
  - 프로세스 제어
  - 파일 조작
  - 장치 조작
  - 정보 유지보수
  - 통신과 보호

- 프로세스 제어를 위한 System Call에는 fork, exec, wait 등이 있습니다.

</details>

<details>
  <summary>PCB란 무엇인가요?</summary>
  <br>

- **Process Control Block**으로 process 정보를 저장하는 곳입니다.
- `Context Switching`시 이전 작업을 저장하기 위해서 필요합니다. 
- `Linked List`방식으로 관리합니다.

</details>

<details>
  <summary>Context Switching이란 무엇인가요?</summary>
  <br>

- CPU가 이전의 프로세스 상태를 PCB에 보관 후 다른 프로세스 정보를 PCB에 읽어 레지스터에 적재하는 과정입니다.
- CPU가 놀지 않게 만들며 빠른 일처리를 제공하기 위한 것입니다.
- 보통 Interrupt 또는 CPU 사용 허가 시간 초과시 발생


![프로세스 상태](../image/ProcessState.jpeg)



### 비동기 처리의 장점
  - context switching 발생하지 않는다.
</details>

<details>
  <summary>IPC란 무엇인가요?</summary>
  <br>

- 프로세스는 독립적인 구조를 가지기에 통신을 해야합니다. 이를 가능하게 해주는 것이 Inter Process Communication이라 불리는 IPC통신입니다.
- 프로세스는 커널이 제공하는 IPC설비를 이용해 프로세스간 통신을 할 수 있게 됩니다.
- IPC 통신에서 프로세스 간 데이터를 동기화하고 보호하기 위해 `세마포어`와 `뮤텍스`를 사용합니다.

</details>

<details>
  <summary>CPU 스케줄링에 대하여 설명해 주세요.</summary>
  <br>

- 정해져 있는 자원을 분배하여 프로세스가 CPU를 사용할 수 있게 결정하는 정책입니다.
- 종류로는 크게 선점(preemptive) 스케줄링과 비선점(non-preemptive) 스케줄링으로 나누어져있습니다.

- 선점(preemptive) 스케줄링
  - 하나의 프로세스가 CPU를 할당받아 실행하고 있을 때, 우선순위가 높은 프로세스가 CPU를 강제로 빼앗아 사용할 수 있는 기법입니다.
  - 처리 시간 예측이 어렵고 선점으로 인한 오버헤드가 발생한다는 단점이 있습니다.
  - ex) `Priority Scheduling`, `Round Robin`, `Multilevel-Queue(다단계 큐)`, `Multilevel-Feedback-Queue(다단계 피드백 큐)`

- 비선점(non-preemptive) 스케줄링
  - 이미 할당된 CPU를 다른 프로세스가 강제로 빼앗아 사용할 수 없는 기법입니다.
  - 공정하며 처리 시간 예측이 용이하다는 장점이 있지만 긴급응답을 요청하는 작업에는 좋지 않다는 단점도 존재합니다.
  - ex) `FCFS(First Come First Served)`, `SJF(Shortest Job First)`, `HRN(Highest Response-ratio Next)`

- 척도
  - `Response Time` : 작업이 처음 실행되기까지 걸린 시간
  - `Turnaround Time` : 실행 시간과 대기 시간을 모두 합한 시간으로 작업이 완료될 때 까지 걸리는 시간

</details>

<details>
  <summary>데드락(교착 상태)가 뭔가요? 발생 조건에 대해 말해보세요.</summary>
  <br>

- 교착 상태로 두 개 이상의 프로세스나 스레드가 무한히 다음 자원을 기다리며 다음 처리를 못하는 상태입니다.
- 발생조건으로는 `상호배제(Mutual exclusion)`, `점유 대기(Hold and wait)`, `비선점(Non-Preemptive)`, `순환 대기(Circular wait)`가 있습니다.
- 처리 방법으로는 `예방(Prevent)`, `회피(Avoidance)`, `탐지(Detection)`, `회복(Recovery)`이있습니다.

</details>

<details>
  <summary>세마포어(Semaphore)와 뮤텍스(Mutex)에 대하여 각각 설명하고 차이점을 설명해주세요.</summary>
  <br>

- `세마포어(Semaphore)`
  - 멀티프로그래밍 환경에서 공유 자원에 대한 접근을 제한하는 방법입니다.
  - 현재 공유 자원에 접근할 수 있는 쓰레드/프로세스의 수를 나타내는 값을 두어 상호 배제를 달성하는 기법입니다.

- `뮤텍스(Mutex)`
  - `상호 배제(Mutual Exclusion)`의 약자이며 임계 영역을 가진 쓰레드들의 실행 시간이 서로 겹치지 않고 각각 단독으로 실행되게 하는 기술입니다.
  - 공유 자원에 대한 접근 조율을 위해 lock과 unlock을 사용합니다.

- **차이점**
  - 가장 큰 차이는 **동기화 갯수**입니다. 뮤텍스는 동기화 대상이 오직 하나뿐이지만 세마포어는 동기화 대상이 하나 이상일 때 사용합니다.
  - 세마포어는 뮤텍스가 될 수 있지만 뮤텍스는 세마포어가 될 수 없습니다.
  - 세마포어는 소유할 수 없지만 뮤텍스는 소유가능하며 소유주가 이에 대한 책임을 집니다.

</details>

<details>
  <summary>페이징과 세그먼테이션에 대하여 설명해주세요.</summary>
  <br>

- `페이징(Paging)`
  - 페이지 단위의 논리-물리 주소 기법
  - 논리 주소 공간이 하나의 연속적인 물리 공간에 들어가야하는 제약을 해결하기 위한 기법
  - 논리 주소 공간과 물리 주소 공간을 분이해야함(주소의 동적 재배치 허용)
  - 외부 단편화 X
  - 변환을 위한 MMU(Memory Management Unit) 필요

- `세그먼테이션(Segmentation)`
  - 사용자/프로그래머 관점의 메모리 관리 기법
  - 논리적 단위(세그먼트)로 나누므로 미리 분할하는 것이 아닌 메모리 사용 시점에 할당

- **외부단편화** vs **내부단편화**
  
  **외부단편화** : 작업보다 많은 공간이 있더라도 실제로 그 작업을 받아들일 수 없는 경우(메모리 배치에 따라 발생하는 문제)
  
  **내부단편화** : 작업에 필요한 공간보다 많은 공간을 할당받음으로써 발생하는 내분의 사용 불가능한 공간

- 페이지 교체 알고리즘

  OPT : 최적 교체. 앞으로 가장 오랫동안 사용하지 않을 페이지 교체 (실현 가능성 희박)

  FIFO : 메모리가 할당된 순서대로 페이지를 교체
  
  LRU : 최근에 가장 오랫동안 사용하지 않은 페이지를 교체
  
  LFU : 사용 빈도가 가장 적은 페이지를 교체
  
  NUR : 최근에 사용하지 않은 페이지를 교체


</details>

<details>
  <summary>동시성(Concurrency)과 병렬성(Parallelism)에 대하여 각각 설명하고 차이점을 설명해주세요.</summary>
  <br>

### 동시성(Concurrency)
  - 하나의 코어에서 여러 스레드가 번갈아가며 실행하는 방식입니다.
  - 동시에 실행하는 것이 아니라 CPU가 작업마다 시간을 분할해 적절하게 context switching을 해서 동시에 실행되는 것처럼 보이게 합니다.
  - `핵심 목표` : 유휴 시간을 최소화

### 병렬성(Parallelism)
  - 멀티 코어에서 여러 스레드를 동시에 실행하는 방식입니다.
  
  - 여러 작업을 다른 코어, 다른 프로세스, 별도의 컴퓨터 등에서 동시에 실행할 수 있다. 그래서 병렬 처리가 성능 향상에 필수적이라고도 합니다.

### Concurrency vs Parallelism
  - 동시성은 여러 task를 계속 번갈아가면서 실행합니다. task 1이 사용하던 자원이 있다고 가정하고 task1이 미처 끝나기 전에 task 2가 같은 자원을 접근한다면? 자원의 값이 변경되며 서로의 실행 결과에 미칠 수 있습니다. 또 task를 어떤 기준으로 선택하고 교환할 것인지도 고려해야 합니다. 따라서 Race Condition, Deadlock, Starvation 등의 문제가 생길 수 있습니다.
  
  - 병렬성은 여러 task가 어떤 자원을 공유하고 있는지 고려해야 하기 때문에 메모리 손상, 누수 등의 문제가 발생할 수 있습니다. 

### More
- `Race Condition`: 여러 프로세스가 하나의 자원에 접근해 서로의 실행 결과에 영향을 주는 현상
- `Deadlock`: 여러 프로세스가 서로 상대방의 작업이 끝나기를 무한히 기다리는 현상
- `Starvation`: 특정 프로세스가 우선순위가 낮아 원하는 자원을 계속 할당 받지 못하는 현상

</details>

<details>
  <summary>셸(shell)에 대하여 설명해주세요.</summary>
  <br>

- 리눅스의 셸은 명령어와 프로그램을 실행할 때 사용하는 인터페이스입니다.
- 셸은 커널(Kernel)과 사용자간의 다리역할을 하는 것으로 사용자로부터 명령을 받아 그것을 해석하고 프로그램을 실행하는 역할을 합니다.
![Linux Shell](../image/LinuxShell.png)

### 셸의 기능 
1. 사용자와 커널 사이에서 명령을 해석해 전달하는 명령어 해석기 기능이 있습니다.
2. 셸은 자체 내에 프로그래밍 기능이 있어서 프로그램을 작성할 수 있습니다. 셸 프로그래밍 기능을 이용하면 여러 명령을 사용해 반복적으로 수행하는 작업을 하나의 프로그램으로 제작 할 수 있습니다. 셸 프로그램을 셸 스크립트라고 부릅니다.
3. 사용자 환경 설정의 기능 - 초기화 파일 기능을 이용해 사용자의 환경을 설정할 수 있습니다. 로그인 할 때 이 초기화 파일이 실행되서 사용자의 초기 환경이 설정됩니다. 셸을 공부하는데 가장 중요한 것 중 하나가 환경변수의 이해입니다.

</details>

<details>
  <summary>동기(Synchronous)와 비동기(Asynchronous)에 대하여 설명해주세요.</summary>
  <br>

- 동기(Synchronous)
  - 호출하는 함수 A가 호출되는 함수 B의 작업 완료 후 리턴을 기다리거나, 바로 리턴 받더라도 미완료 상태이라면 작업 완료 여부를 스스로 계속 확인하는 것입니다.
- 비동기(Asynchronous)
  - 함수 A는 함수 B를 호출한 후로 함수 B의 작업 완료 여부에는 신경쓰지 않는 것입니다.
  <!-- - 함수 A가 함수 B를 호출할 때 콜백 함수를 함께 전달해서, 함수 B의 작업이 완료되면 함께 보낸 콜백 함수를 실행한다. -->


</details>